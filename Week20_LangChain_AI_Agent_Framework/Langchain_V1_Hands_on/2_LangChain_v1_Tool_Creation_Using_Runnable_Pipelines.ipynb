{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7fb98-315f-4a8e-9d3b-6351522ebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain v1 Tool Creation Using Runnable Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5009d34f-5766-4784-bfe3-ca44786d5dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Question: What is LangGraph in LangChain?\n",
      "Tool Answer: LangGraph in LangChain is a framework designed to facilitate the construction and management of complex workflows involving language models. It allows users to create directed graphs where nodes represent various components or tasks, such as data processing, model inference, or API calls, and edges represent the flow of data between these components. This structure enables users to build more sophisticated applications by organizing and orchestrating multiple language model interactions and data transformations in a modular and reusable way. LangGraph enhances the capabilities of LangChain by providing a visual and programmatic way to manage dependencies and execution order in language model applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# üîê Load API key\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# üî∏ Step 1: Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# üî∏ Step 2: Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Answer clearly: {question}\"\n",
    ")\n",
    "\n",
    "# üî∏ Step 3: Runnable chain (v1)\n",
    "chain = prompt | llm\n",
    "\n",
    "# üî∏ Step 4: Tool definition (v1 style)\n",
    "@tool\n",
    "def simple_qa(question: str) -> str:\n",
    "    \"\"\"A basic LLM tool that answers clear questions\"\"\"\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    return response.content\n",
    "\n",
    "# üî∏ Step 5: Use the tool\n",
    "query = \"What is LangGraph in LangChain?\"\n",
    "answer = simple_qa.invoke(query)\n",
    "\n",
    "# üñ®Ô∏è Output\n",
    "print(\"User Question:\", query)\n",
    "print(\"Tool Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca932b6a-eb85-464a-a7d8-b05d3a43dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_15848\\229898575.py:13: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_15848\\229898575.py:19: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Question: What is LangGraph in LangChain?\n",
      "\n",
      "Tool Answer: LangGraph in LangChain is a graph database that stores and manages language data, including words, phrases, and their relationships. It is a key component of the LangChain platform, allowing for efficient storage and retrieval of language information for various applications.\n"
     ]
    }
   ],
   "source": [
    "#old version\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "# üîê Load API keys from .env\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# üî∏ Step 1: Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# üî∏ Step 2: Create a prompt template\n",
    "prompt = PromptTemplate.from_template(\"Answer clearly: {question}\")\n",
    "\n",
    "# üî∏ Step 3: Build the LLMChain\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# üî∏ Step 4: Wrap LLMChain as a Tool\n",
    "qa_tool = Tool(\n",
    "    name=\"Simple QA\",\n",
    "    func=qa_chain.run,\n",
    "    description=\"A basic LLM chain that answers clear questions\"\n",
    ")\n",
    "\n",
    "# üî∏ Step 5: Use the Tool directly\n",
    "query = \"What is LangGraph in LangChain?\"\n",
    "answer = qa_tool.run(query)\n",
    "\n",
    "# üñ®Ô∏è Output\n",
    "print(\"\\nUser Question:\", query)\n",
    "print(\"\\nTool Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b0875-ab57-4457-97bf-827b3d0bc955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6779eaf-390d-47be-8bce-38cac33f6dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchainai)",
   "language": "python",
   "name": "langchainai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
