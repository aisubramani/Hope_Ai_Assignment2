{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4c6256-b17e-447d-b897-f777ef308fde",
   "metadata": {},
   "source": [
    "# Modern LangChain v1 Example Using Runnable API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc314b8a-2c1d-496d-af1f-1cae803ef061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Question: What is LangGraph in LangChain?\n",
      "\n",
      "LLM Answer: LangGraph in LangChain is a framework designed to facilitate the creation and management of complex workflows involving language models. It allows users to define and visualize the relationships between different components, such as prompts, models, and data sources, in a graph-like structure. This enables more efficient orchestration of tasks, better organization of code, and improved collaboration when building applications that leverage language models. LangGraph helps streamline the development process by providing tools for connecting various elements and managing their interactions effectively.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# üîê Load API key\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# üî∏ Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# üî∏ Create Prompt Template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Answer clearly: {question}\"\n",
    ")\n",
    "\n",
    "# üî∏ Runnable chain (NEW STYLE)\n",
    "chain = prompt | llm\n",
    "\n",
    "# üöÄ Run a query\n",
    "query = \"What is LangGraph in LangChain?\"\n",
    "response = chain.invoke({\"question\": query})\n",
    "\n",
    "# üñ®Ô∏è Output\n",
    "print(\"\\nUser Question:\", query)\n",
    "print(\"\\nLLM Answer:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b42fd-6a24-44a7-93b2-e5494d1be359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8044c3b9-4822-4ab8-90a9-5dc37df84346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_18220\\4093061316.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_18220\\4093061316.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_18220\\4093061316.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Question: What is LangGraph in LangChain?\n",
      "\n",
      "LLM Answer: LangGraph in LangChain is a graph database that stores and manages language data, including words, phrases, and their relationships. It is used to facilitate natural language processing and understanding within the LangChain platform.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# üîê Load API key\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# üî∏ Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# üî∏ Create Prompt Template\n",
    "prompt = PromptTemplate.from_template(\"Answer clearly: {question}\")\n",
    "\n",
    "# üî∏ Create LLMChain\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# üöÄ Run a query\n",
    "query = \"What is LangGraph in LangChain?\"\n",
    "response = qa_chain.run({\"question\": query})\n",
    "\n",
    "# üñ®Ô∏è Output\n",
    "print(\"\\nUser Question:\", query)\n",
    "print(\"\\nLLM Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bd59b-a404-4357-be34-41d7834d8900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchainai)",
   "language": "python",
   "name": "langchainai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
