{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4f22c3-2303-45a5-b816-affa53a76312",
   "metadata": {},
   "source": [
    "# Output Parsers in LangChain v1\n",
    "\n",
    "üß© What is an Output Parser?\n",
    "\n",
    "LLM gives text like:\n",
    "\n",
    "Apple, Banana, Mango\n",
    "\n",
    "\n",
    "Parser converts it into:\n",
    "\n",
    "[\"Apple\", \"Banana\", \"Mango\"]\n",
    "\n",
    "\n",
    "So your Python code can use it.\n",
    "\n",
    "Prompt\n",
    "   ‚Üì\n",
    "LLM\n",
    "   ‚Üì\n",
    "Raw Text\n",
    "   ‚Üì\n",
    "Parser\n",
    "   ‚Üì\n",
    "Python Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7342b4a-e59a-45ea-84cb-ae4df380f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîß LLM Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# ----------------------------\n",
    "# LLM\n",
    "# ----------------------------\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28420e65-297a-47d5-86fb-d8ca46a354f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are three fruits:\n",
      "\n",
      "1. Apple\n",
      "2. Banana\n",
      "3. Orange\n"
     ]
    }
   ],
   "source": [
    "#üß† 1Ô∏è‚É£ StrOutputParser\n",
    "\n",
    "#Just returns text as string\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"List three fruits\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71fa74bc-35a2-42d6-bfe0-6940e30700a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Banana', 'Cherry']\n"
     ]
    }
   ],
   "source": [
    "# üß† 2Ô∏è‚É£ CommaSeparatedListOutputParser\n",
    "\n",
    "# Splits text into a list\n",
    "\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"List three fruits separated by commas\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "print(chain.invoke({}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4196624c-2346-44fe-bd6d-f6a9ff5050da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fruit': 'apple', 'color': 'red'}\n"
     ]
    }
   ],
   "source": [
    "# üß† 3Ô∏è‚É£ JsonOutputParser\n",
    "#ResponseSchema + StructuredOutputParser\n",
    "\n",
    "#Force LLM to return JSON-like structure\n",
    "# LLM ‚Üí JSON ‚Üí Python object\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give a fruit and its color as JSON.\\n{format}\\n\"\n",
    ")\n",
    "\n",
    "chain = prompt.partial(format=parser.get_format_instructions()) | llm | parser\n",
    "\n",
    "print(chain.invoke({}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d8e326-3baa-432f-8173-eed2483589a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit='Apple' color='Red'\n",
      "Apple Red\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ PydanticOutputParser\n",
    "# Best for APIs, strict typing\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Fruit(BaseModel):\n",
    "    fruit: str\n",
    "    color: str\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Fruit)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give a fruit and its color.\\n{format}\\n\"\n",
    ")\n",
    "\n",
    "chain = prompt.partial(format=parser.get_format_instructions()) | llm | parser\n",
    "\n",
    "result = chain.invoke({})\n",
    "\n",
    "print(result)\n",
    "print(result.fruit, result.color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f946382-f55d-4855-9802-028a02ac464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 1.2.0\n",
      "langchain_core: 1.2.7\n",
      "langchain_community: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import langchain_core\n",
    "import langchain_community\n",
    "\n",
    "print(\"langchain:\", langchain.__version__)\n",
    "print(\"langchain_core:\", langchain_core.__version__)\n",
    "print(\"langchain_community:\", langchain_community.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6cf4e3-cd13-4167-ae72-76e348cd6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                                1.2.0\n",
      "langchain-classic                        1.0.1\n",
      "langchain-community                      0.4.1\n",
      "langchain-core                           1.2.7\n",
      "langchain-openai                         1.1.7\n",
      "langchain-text-splitters                 1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | findstr langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585338ca-11a1-435f-b2e6-b571a69459b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langgraph                                1.0.5\n",
      "langgraph-checkpoint                     3.0.1\n",
      "langgraph-prebuilt                       1.0.5\n",
      "langgraph-sdk                            0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | findstr langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e48672-a598-44ae-b235-b135c33fa0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch: 2.5.1+cu121\n",
      "Transformers: 4.57.3\n"
     ]
    }
   ],
   "source": [
    "import sys, torch, transformers\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7d26f6-41cb-43bf-bb7e-fc25562a381a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1663fc69-bd74-48e2-be58-2c7958284c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU working: 2499.881591796875\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(10000, 10000, device=\"cuda\")\n",
    "y = torch.mm(x, x)\n",
    "print(\"GPU working:\", y.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9cf531-02e5-424f-ad02-d20a06b3b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your NVIDIA GPU + CUDA + PyTorch + Python 3.12.7 stack is running at full speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain AI Python 3.12.7",
   "language": "python",
   "name": "langchainai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
