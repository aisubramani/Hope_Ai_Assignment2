{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfc6386-b600-452d-83c7-58af8a1ba475",
   "metadata": {},
   "source": [
    "# Retrival Based two Agent: (LLaMA 3.1 (8B)) 1. REASONING AGENT + 2. RETRIEVER AGENT(RAG)\n",
    "\n",
    "üü† LLaMA 3.1 (Local) ‚Äî model = \"llama3.1:8b\"\n",
    "\n",
    "Retriever Agent runs fully offline with vector DB.\n",
    "\n",
    "Reasoning Agent is LLaMA 3.1 via Ollama.\n",
    "\n",
    "No API key, no cloud dependency.\n",
    "\n",
    "Slightly slower but privacy-preserving.\n",
    "\n",
    "Best for PrivateRAG and regulated environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be352167-e4be-4b46-80af-43435d9576f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "Question: What is Artificial Intelligence?\n",
      "Answer: Artificial Intelligence (AI) is a branch of computer science that focuses on building systems capable of performing tasks that normally require human intelligence. These tasks include reasoning, learning, problem-solving, perception, and language understanding. The term Artificial Intelligence was first introduced by John McCarthy in 1956 during the Dartmouth Conference.\n",
      "\n",
      "--------------------------------\n",
      "Question: What is your salary?\n",
      "Answer: Not found in the document.\n",
      "\n",
      "--------------------------------\n",
      "Question: Explain agent-based AI systems.\n",
      "Answer: According to the context (Page 9), Agent-based systems consist of autonomous components called agents. Each agent has:\n",
      "\n",
      "- A goal\n",
      "- Memory\n",
      "- Decision logic\n",
      "\n",
      "Multi-agent systems improve reliability and scalability.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# TWO-AGENT LOCAL RAG ‚Äî LLaMA 3.1 (8B) via OLLAMA\n",
    "# =========================================================\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import ollama\n",
    "\n",
    "# =========================================================\n",
    "# AGENT 2: LLaMA 3.1 (8B) ‚Äî REASONING AGENT\n",
    "# =========================================================\n",
    "class LlamaAgent:\n",
    "    def answer(self, context, question):\n",
    "        prompt = f\"\"\"\n",
    "You are a document-grounded AI assistant.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the provided context.\n",
    "- If the answer is not in the context, say exactly:\n",
    "  Not found in the document.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1:8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# AGENT 1: RETRIEVER AGENT\n",
    "# =========================================================\n",
    "class RetrieverAgent:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        self.client = chromadb.Client()\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=\"llama31-8b-docs\"\n",
    "        )\n",
    "        self._ingest_pdf(pdf_path)\n",
    "\n",
    "    def _ingest_pdf(self, pdf_path):\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\\n\".join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "        words = text.split()\n",
    "        chunks = [\n",
    "            \" \".join(words[i:i + 300])\n",
    "            for i in range(0, len(words), 300)\n",
    "        ]\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            self.collection.add(\n",
    "                documents=[chunk],\n",
    "                ids=[str(i)],\n",
    "                embeddings=[self.embedder.encode(chunk).tolist()]\n",
    "            )\n",
    "\n",
    "    def retrieve(self, question, k=3):\n",
    "        q_embedding = self.embedder.encode(question).tolist()\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[q_embedding],\n",
    "            n_results=k\n",
    "        )\n",
    "        return \"\\n\".join(results[\"documents\"][0])\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ORCHESTRATOR\n",
    "# =========================================================\n",
    "retriever_agent = RetrieverAgent(\"Ai_Test_Book.pdf\")\n",
    "llama_agent = LlamaAgent()\n",
    "\n",
    "# =========================================================\n",
    "# LIMIT TO ONLY 3 QUESTIONS\n",
    "# =========================================================\n",
    "MAX_QUESTIONS = 3\n",
    "question_count = 0\n",
    "\n",
    "questions = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"What is your salary?\",\n",
    "    \"Explain agent-based AI systems.\"\n",
    "]\n",
    "\n",
    "# =========================================================\n",
    "# RUN TWO-AGENT LOCAL RAG\n",
    "# =========================================================\n",
    "for question in questions:\n",
    "    if question_count >= MAX_QUESTIONS:\n",
    "        print(\"‚ùå Question limit reached. Session ended.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n--------------------------------\")\n",
    "    print(f\"Question: {question}\")\n",
    "\n",
    "    # AGENT 1 ‚Üí RETRIEVE\n",
    "    context = retriever_agent.retrieve(question)\n",
    "\n",
    "    # AGENT 2 ‚Üí REASON\n",
    "    answer = llama_agent.answer(context, question)\n",
    "\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    question_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bfe07-c227-4c25-8c24-446ccf91bb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
