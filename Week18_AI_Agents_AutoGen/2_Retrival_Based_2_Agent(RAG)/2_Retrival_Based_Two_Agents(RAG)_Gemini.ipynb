{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48a22a5-96cc-4991-a523-df3007391ae1",
   "metadata": {},
   "source": [
    "# Retrival Based two Agent: (Gemini) 1. REASONING AGENT + 2. RETRIEVER AGENT(RAG)\n",
    "\n",
    "üîµ Gemini ‚Äî MODEL_NAME = \"models/gemini-flash-latest\"\n",
    "\n",
    "Retriever Agent: local embeddings + vector DB (Chroma).\n",
    "\n",
    "Reasoning Agent: Gemini Flash (cloud).\n",
    "\n",
    "Very fast and low-cost for RAG demos.\n",
    "\n",
    "Manual agent orchestration (no native AutoGen).\n",
    "\n",
    "Best for rapid prototyping and research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d71be6-d1b4-430d-83f9-725066abd98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "Question: What is Artificial Intelligence?\n",
      "Answer: Artificial Intelligence (AI) is a branch of computer science that focuses on building systems capable of performing tasks that normally require human intelligence. These tasks include reasoning, learning, problem-solving, perception, and language understanding.\n",
      "\n",
      "--------------------------------\n",
      "Question: What is your salary?\n",
      "Answer: Not found in the document.\n",
      "\n",
      "--------------------------------\n",
      "Question: Explain agent-based AI systems.\n",
      "Answer: Agent-based systems consist of autonomous components called agents. Each agent has a goal, memory, and decision logic. Multi-agent systems improve reliability and scalability.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# TWO-AGENT GEMINI RAG SYSTEM\n",
    "# =========================================================\n",
    "\n",
    "from google import genai\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# =========================================================\n",
    "# AGENT 2: GEMINI (LLM AGENT)\n",
    "# =========================================================\n",
    "GEMINI_API_KEY = \"--your GEMINI Key--\"\n",
    "MODEL_NAME = \"models/gemini-flash-latest\"\n",
    "\n",
    "llm_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "class GeminiAgent:\n",
    "    def answer(self, context, question):\n",
    "        prompt = f\"\"\"\n",
    "You are a document-grounded AI assistant.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the provided context.\n",
    "- If the answer is not found, say exactly:\n",
    "  Not found in the document.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        response = llm_client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# AGENT 1: RETRIEVER AGENT\n",
    "# =========================================================\n",
    "class RetrieverAgent:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        self.client = chromadb.Client()\n",
    "        self.collection = self.client.get_or_create_collection(\"two-agent-docs\")\n",
    "\n",
    "        self._ingest_pdf(pdf_path)\n",
    "\n",
    "    def _ingest_pdf(self, pdf_path):\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\\n\".join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "        words = text.split()\n",
    "        chunks = [\n",
    "            \" \".join(words[i:i+300])\n",
    "            for i in range(0, len(words), 300)\n",
    "        ]\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            self.collection.add(\n",
    "                documents=[chunk],\n",
    "                ids=[str(i)],\n",
    "                embeddings=[self.embedder.encode(chunk).tolist()]\n",
    "            )\n",
    "\n",
    "    def retrieve(self, question, k=3):\n",
    "        q_emb = self.embedder.encode(question).tolist()\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[q_emb],\n",
    "            n_results=k\n",
    "        )\n",
    "        return \"\\n\".join(results[\"documents\"][0])\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ORCHESTRATOR (AGENT COORDINATOR)\n",
    "# =========================================================\n",
    "retriever_agent = RetrieverAgent(\"Ai_Test_Book.pdf\")\n",
    "llm_agent = GeminiAgent()\n",
    "\n",
    "# =========================================================\n",
    "# LIMIT TO 3 QUESTIONS\n",
    "# =========================================================\n",
    "MAX_QUESTIONS = 3\n",
    "question_count = 0\n",
    "\n",
    "questions = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"What is your salary?\",\n",
    "    \"Explain agent-based AI systems.\"\n",
    "]\n",
    "\n",
    "# =========================================================\n",
    "# RUN TWO-AGENT RAG\n",
    "# =========================================================\n",
    "for question in questions:\n",
    "    if question_count >= MAX_QUESTIONS:\n",
    "        print(\"‚ùå Question limit reached. Session ended.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n--------------------------------\")\n",
    "    print(f\"Question: {question}\")\n",
    "\n",
    "    # AGENT 1 ‚Üí RETRIEVE\n",
    "    context = retriever_agent.retrieve(question)\n",
    "\n",
    "    # AGENT 2 ‚Üí REASON\n",
    "    answer = llm_agent.answer(context, question)\n",
    "\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    question_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480b760-8132-4596-bbae-98f1f60a5eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bfe07-c227-4c25-8c24-446ccf91bb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
