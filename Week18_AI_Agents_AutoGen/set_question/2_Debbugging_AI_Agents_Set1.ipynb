{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65225a6-ab3b-423f-8da9-ea88f7bb8beb",
   "metadata": {},
   "source": [
    "# Debbugging AI Agents Set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af852a0-b278-4e3c-a8e2-0f424d27c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected ALL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8a32b6-3634-449d-b4d3-33d004dd65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAgent1\u001b[0m (to Agent2):\n",
      "\n",
      "Hi, calculate 5 * 3\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAgent2\u001b[0m (to Agent1):\n",
      "\n",
      "The calculation for \\( 5 \\times 3 \\) is \\( 15 \\).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAgent1\u001b[0m (to Agent2):\n",
      "\n",
      "The result of \\( 5 \\times 3 \\) is \\( 15 \\).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAgent2\u001b[0m (to Agent1):\n",
      "\n",
      "That's correct! The result of \\( 5 \\times 3 \\) is indeed \\( 15 \\).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (3ea4135a-23e8-4953-8b51-e0a15fcdc2a1): Maximum turns (2) reached\u001b[0m\n",
      "ChatResult(chat_id=124529965874882940517911431680659039602, chat_history=[{'content': 'Hi, calculate 5 * 3', 'role': 'assistant', 'name': 'Agent1'}, {'content': 'The calculation for \\\\( 5 \\\\times 3 \\\\) is \\\\( 15 \\\\).', 'role': 'user', 'name': 'Agent2'}, {'content': 'The result of \\\\( 5 \\\\times 3 \\\\) is \\\\( 15 \\\\).', 'role': 'assistant', 'name': 'Agent1'}, {'content': \"That's correct! The result of \\\\( 5 \\\\times 3 \\\\) is indeed \\\\( 15 \\\\).\", 'role': 'user', 'name': 'Agent2'}], summary=\"That's correct! The result of \\\\( 5 \\\\times 3 \\\\) is indeed \\\\( 15 \\\\).\", cost={'usage_including_cached_inference': {'total_cost': 6.015e-05, 'gpt-4o-mini-2024-07-18': {'cost': 6.015e-05, 'prompt_tokens': 169, 'completion_tokens': 58, 'total_tokens': 227}}, 'usage_excluding_cached_inference': {'total_cost': 6.015e-05, 'gpt-4o-mini-2024-07-18': {'cost': 6.015e-05, 'prompt_tokens': 169, 'completion_tokens': 58, 'total_tokens': 227}}}, human_input=[])\n"
     ]
    }
   ],
   "source": [
    "#1. Correct Code\n",
    "#Invalid Gemini configuration\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"api_key\": \"your key\"\n",
    "}\n",
    "\n",
    "agent1 = ConversableAgent(\n",
    "    name=\"Agent1\",\n",
    "    system_message=\"You are a helpful AI assistant that performs calculations.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "agent2 = ConversableAgent(\n",
    "    name=\"Agent2\",\n",
    "    system_message=\"You are an AI assistant that verifies calculations.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response = agent1.initiate_chat(\n",
    "    agent2,\n",
    "    message=\"Hi, calculate 5 * 3\",\n",
    "    max_turns=2\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f63711-6ea5-4e24-a16b-c53120265a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "Artificial Intelligence (AI) involves machines mimicking human intelligence to perform tasks like understanding language and decision-making. \n",
      "\n",
      "The two main types of AI are:\n",
      "\n",
      "1. **Narrow AI**: Specialized in specific tasks (e.g., voice recognition).\n",
      "2. **General AI**: Theoretical AI that would think like a human, which doesn't exist yet.\n",
      "\n",
      "AI methods include:\n",
      "\n",
      "- **Machine Learning (ML)**: Enables computers to learn from data, including supervised, unsupervised, and reinforcement learning.\n",
      "- **Deep Learning**: A subset of ML using neural networks to detect complex patterns.\n",
      "- **Natural Language Processing (NLP)**: Focuses on computer understanding and generating human language.\n",
      "\n",
      "AI is rapidly evolving, impacting fields like healthcare and finance, while also raising ethical concerns.\n"
     ]
    }
   ],
   "source": [
    "# 2. corrected Code\n",
    "# Missing system_message & llm_config\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"api_key\": \"your key\"\n",
    "}\n",
    "\n",
    "agent1 = ConversableAgent(\n",
    "    name=\"Agent1\",\n",
    "    system_message=\"You explain concepts clearly.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "agent2 = ConversableAgent(\n",
    "    name=\"Agent2\",\n",
    "    system_message=\"You simplify explanations.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "agent3 = ConversableAgent(\n",
    "    name=\"Agent3\",\n",
    "    system_message=\"You summarize responses briefly.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response1 = agent1.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is AI?\"}]\n",
    ")\n",
    "\n",
    "response2 = agent2.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": response1}]\n",
    ")\n",
    "\n",
    "response3 = agent3.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": response2}]\n",
    ")\n",
    "\n",
    "print(response3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7c9d91-a2c2-45f9-8453-6ef194c89ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15016\\anaconda3\\envs\\aiagent\\Lib\\site-packages\\autogen\\oai\\gemini.py:1098: UserWarning: Cost calculation is not implemented for model models/gemini-flash-latest. Cost will be calculated zero.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDEA:\n",
      " {'content': 'This startup idea focuses on leveraging high-frequency, multimodal data and advanced AI to transition chronic disease management from reactive treatment to **predictive prevention**.\\n\\n---\\n\\n## Startup Idea: **KAIROS Predictive Health (KPH)**\\n\\n### 1. The Problem\\n\\nCurrent chronic disease management (CDM), particularly for high-cost, high-complication conditions like Type 2 Diabetes, Hypertension, and early Congestive Heart Failure (CHF), is inherently reactive.\\n\\n*   **Siloed Data:** EHR data is episodic, while wearable/device data (CGM, smartwatches) is continuous but often lacks context.\\n*   **Adherence Failure:** Patients struggle to connect daily decisions (sleep, stress, diet) to long-term biometric trends, leading to poor adherence to medication and lifestyle changes.\\n*   **Delayed Intervention:** Providers typically intervene only after a metric has crossed a major threshold (e.g., A1C rises, hospitalization).\\n\\n**The Gap:** There is no platform that can synthesize high-frequency physiological data with environmental/behavioral context to predict specific adverse events or metric deviations hours or days *before* they occur.\\n\\n### 2. The Solution: Predictive Micro-Intervention Engine\\n\\nKPH develops an **Event-Driven Predictive Modeling (EDPM) platform** that creates a constantly evolving digital twin of the patient’s physiology and behavior.\\n\\nThe platform provides **closed-loop feedback** to both the patient and the care team, issuing highly targeted \"micro-interventions\" designed to prevent metric deviations.\\n\\n#### **Core Functionality:**\\n\\n1.  **Data Ingestion Layer (Heterogeneous Fusion):** Ingests and standardizes data from:\\n    *   Continuous Glucose Monitors (CGM)\\n    *   Smart Patches/Rings (HRV, Sleep, SpO2, Temperature)\\n    *   Connected Devices (BP cuffs, Scales)\\n    *   Environmental Factors (Local weather, validated GPS/location-based stress context)\\n    *   Validated Subjective Input (Prompted data on mood, pain, perceived stress).\\n\\n2.  **KAIROS Prediction Engine (AI/ML):** Uses a combination of Deep Learning (RNNs, LSTMs) and Reinforcement Learning to identify specific, time-sensitive patterns:\\n    *   **Goal:** Predict a significant metric failure (e.g., sustained blood sugar > 250 mg/dL, or BP spike > 145/95) 4 to 24 hours in advance.\\n    *   **Insight:** The engine learns that \"A 20-minute drop in HRV + 4 hours of suboptimal sleep + consumption of X food item usually leads to a +30% glucose elevation spike 12 hours later.\"\\n\\n3.  **Personalized Prescriptive Nudge System:** When an EDPM prediction hits a certain confidence threshold, KPH delivers a precise, personalized intervention via a patient-facing app:\\n    *   *Example Nudge (Predicting a PM Glucose Spike):* \"We are detecting patterns that suggest a significant glucose elevation spike may occur between 8 PM and 10 PM tonight. Please consider taking a brisk 15-minute walk immediately after your 6 PM meal, and ensure your evening medication dose is taken with water at 7 PM sharp.\"\\n\\n### 3. The Technology & Innovation\\n\\n#### **Key Innovation: Proactive Pattern Interception**\\n\\nThe innovation is not just collecting more data, but using **Reinforcement Learning (RL)** to dynamically optimize the timing and content of the intervention. The system learns which type of nudge (dietary advice vs. exercise recommendation vs. medication reminder) is most effective for *that specific patient* at *that specific time* to prevent the predicted failure.\\n\\n*   **Technology Stack:** Cloud-native architecture (HIPAA compliant), Federated learning models for privacy, and a proprietary **Biometric Anomaly Score (BAS)** that quantifies the likelihood and severity of an impending health deviation.\\n*   **B2B Model:** KPH partners directly with large health systems, self-insured employers, and specialized clinics (e.g., endocrinology, cardiology) to reduce costly readmissions, slow disease progression, and improve quality-of-life metrics (HEDIS scores).\\n\\n### 4. Market Potential and Go-to-Market Strategy\\n\\n**Target Market:** Chronic Care Management (CCM) programs for patients with multiple comorbidities.\\n\\n**Value Proposition to Payers/Providers:**\\n1.  **Reduced Hospitalization/Readmissions:** By predicting and mitigating crisis events (severe hypoglycemia, hypertensive spikes).\\n2.  **Higher Adherence Rates:** Micro-interventions are easier to follow than generalized advice.\\n3.  **Data Standardization:** KPH provides a centralized, actionable predictive dashboard for the care team, highlighting patients on the verge of a deviation.\\n\\n**Pilot Success Metric:** Demonstrating a measurable decrease (e.g., 20% reduction) in high-severity biometric events and subsequent emergency room utilization among enrolled patients within 12 months.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "ANALYSIS:\n",
      " {'content': '## Startup Idea Analysis: KAIROS Predictive Health (KPH)\\n\\nKAIROS Predictive Health (KPH) is a highly ambitious, frontier-tech solution addressing the single largest cost driver in modern healthcare: chronic disease management. Its success hinges on overcoming significant data integration, regulatory, and AI modeling hurdles.\\n\\n---\\n\\n## Overall Assessment\\n\\n| Metric | Rating | Rationale |\\n| :--- | :--- | :--- |\\n| **Market Opportunity** | Very High | Chronic disease is a multi-trillion-dollar problem. Prediction is the ultimate value unlock. |\\n| **Technological Feasibility**| High Risk | Requires sophisticated fusion of heterogeneous data and novel Reinforcement Learning models to achieve clinical reliability. |\\n| **B2B Value Proposition** | Strong & Quantifiable | Direct path to reducing high-cost events (hospitalizations, readmissions). |\\n| **Scalability** | Medium-High | High integration costs initially, but the predictive model scales well once trained. |\\n| **Regulatory Burden** | Very High | Operating in a clinical decision support space with high liability risk. |\\n\\n**Verdict:** KPH represents a **High-Risk, High-Reward** venture. If the core prediction engine achieves reliable accuracy and is validated, it could fundamentally disrupt the digital health landscape.\\n\\n---\\n\\n## Detailed Analysis of Pros\\n\\n### 1. Market and Financial Alignment (The \"Why Now\")\\n\\n*   **Massive Addressable Market:** Chronic disease costs the US healthcare system trillions annually. Any technology that demonstrably reduces major adverse events (like diabetic ketoacidosis or CHF readmissions) has immediate and quantifiable ROI for payers and providers.\\n*   **Clear Value Proposition to Payers (B2B):** The primary value driver is measured in dollars saved from prevented hospitalizations, readmissions, and urgent care visits. This ties directly into risk-bearing contracts (ACOs) and quality measures (HEDIS/Star ratings), making the sales pitch financially grounded.\\n*   **Addressing the Adherence Problem:** Traditional CDM fails because it relies on generalized advice. KPH\\'s core innovation—using Reinforcement Learning to optimize the **timing and content** of the nudge—is the key to solving patient adherence/burnout, the biggest weakness of current digital therapeutics.\\n\\n### 2. Technological and Data Superiority\\n\\n*   **Multimodal Data Fusion is the Future:** By combining physiological data (CGM, HRV) with contextual data (sleep, stress, environmental), KPH moves beyond simple correlation to true causality detection, enabling more robust predictions.\\n*   **Sophisticated AI Methodology (RL):** Using Reinforcement Learning to manage the closed-loop feedback system is superior to static models. The system learns which interventions work best for *Patient X* at *Time Y* to achieve *Goal Z*, improving accuracy and adherence over time.\\n*   **Predictive Lead Time is Critical:** Predicting a major failure 4 to 24 hours in advance gives the patient and provider a meaningful window for prevention, transforming the clinical workflow from emergency response to scheduled mitigation.\\n\\n---\\n\\n## Detailed Analysis of Cons\\n\\n### 1. Technical & Data Hurdles (The \"Cold Start\" Problem)\\n\\n*   **Data Integration Complexity:** Integrating reliable, continuous feeds from a constantly evolving universe of consumer and medical devices (CGM, Oura, Garmin, BP cuffs, etc.) is a massive, ongoing engineering challenge. Data standardization, normalization, and maintaining HIPAA compliance across all these streams is exceptionally costly.\\n*   **AI Training & Confidence:** To train the predictive models (especially RL models), KPH requires vast quantities of *labeled failure events* combined with the preceding multimodal data sequence. This data is rare and expensive to acquire in clean, clinically validated forms. Without high confidence (e.g., >85% prediction accuracy), providers will not trust the platform, and patients will ignore the nudges.\\n*   **Managing False Positives:** A system that delivers frequent, inaccurate, or irrelevant \"micro-interventions\" will lead to rapid patient alert fatigue and abandonment, destroying the value proposition. The balance between proactive intervention and patient annoyance is delicate.\\n\\n### 2. Regulatory and Clinical Risk\\n\\n*   **Medical Device Classification:** The FDA will scrutinize any software that uses sophisticated algorithms to analyze physiological data and provide \"prescriptive\" recommendations intended to treat or prevent a condition. KPH\\'s \"Prescriptive Nudge System\" is highly likely to be classified as a Software as a Medical Device (SaMD), requiring extensive clinical trials and regulatory clearance (potentially Class II or III).\\n*   **Liability:** If the system predicts a metric failure and advises an action (or inaction) that results in patient harm (e.g., severe hypoglycemia), the liability risk is substantial. This requires strong legal and clinical protocols from day one.\\n*   **Clinical Validation Demand:** Payers and health systems will not adopt the platform without rigorous, peer-reviewed evidence (RCTs) demonstrating that the platform reduces hospitalization rates and improves long-term outcomes at scale.\\n\\n### 3. Execution and Go-to-Market Challenges\\n\\n*   **Long Sales Cycles (B2B Healthcare):** Selling transformative, high-cost solutions to large health systems or payers involves multi-year pilot programs and sales cycles, requiring significant upfront capital burn before generating meaningful revenue.\\n*   **Workflow Integration:** The predictive dashboard must integrate seamlessly into the provider\\'s EHR and existing clinical workflow. If it adds complexity or requires significant new training for care teams, adoption will stall, regardless of the predictive accuracy.\\n*   **Privacy and Security at Scale:** Managing diverse, high-frequency biometric, environmental, and location data streams for thousands of patients demands an enterprise-grade, unbreachable security infrastructure, adding substantial operational cost.\\n\\n---\\n\\n## Recommendations and De-risking Strategy\\n\\nTo de-risk KPH, the founders must focus intensely on narrowing the scope and proving efficacy quickly.\\n\\n| Phase | Strategy | Rationale |\\n| :--- | :--- | :--- |\\n| **Phase 1: Focus & Validation** | **Narrow the Initial Condition:** Do not attempt to tackle T2D, HTN, and CHF simultaneously. Start with a single, high-cost condition where continuous data is plentiful and the adverse event is clearly defined, such as **reducing 30-day readmissions for post-discharge CHF patients.** | CHF readmissions are a high-ROI target (Medicare penalizes them), and the necessary physiological data (weight, BP, HRV) is relatively standardized. This simplifies the data layer and targets immediate financial pain points. |\\n| **Phase 2: Regulatory Strategy**| **Seek De Novo Classification Early:** Engage with the FDA immediately to determine the classification of the predictive engine and prescriptive nudges. If possible, structure the initial offering as a lower-risk \"Clinical Decision Support\" tool, while running parallel trials for a full SaMD submission. | This manages risk and avoids potentially paralyzing delays 18 months into development. |\\n| **Phase 3: Data Integrity** | **Partner with Device Manufacturers:** Negotiate direct API access with major device/CGM providers (e.g., Dexcom, Abbott, Apple, Whoop) to bypass the often-fragmented consumer data layer and ensure data quality and flow consistency. | This is crucial for solving the data ingestion and standardization complexity. |', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "DECISION:\n",
      " {'content': 'This is a **Category-Defining Idea** that addresses the single largest drain on the US economy.\\n\\n**The idea should be pursued, but only under the strict condition that the proposed de-risking strategy is executed immediately and aggressively, focusing on narrow validation and substantial upfront capital raise.**\\n\\n---\\n\\n## Rationale for Pursuit (The \"Why\")\\n\\nKAIROS Predictive Health (KPH) is not merely an improvement on existing digital health; it seeks to fundamentally solve the core failures of chronic disease management (CDM): adherence and the reactive nature of current care.\\n\\n1.  **Massive Financial Alignment:** The value proposition—saving billions by preventing major adverse events—transcends the \"wellness\" or \"engagement\" metrics of most digital health companies. KPH offers hard, quantifiable ROI measured in avoided hospital days and reduced readmission penalties.\\n2.  **Technological Superiority:** The use of Reinforcement Learning (RL) to personalize the *timing and content* of the intervention is the necessary innovation to overcome patient fatigue. This is a genuinely superior approach compared to static models.\\n3.  **If It Works, It Wins:** Given the trillion-dollar chronic disease market, if KPH can achieve and clinically validate an 85%+ accurate prediction rate for a major adverse event 12 hours in advance, it becomes a non-negotiable platform for every large payer and health system. The reward justifies the extraordinary risk.\\n\\n---\\n\\n## Critical Action Plan (The \"How\")\\n\\nThe pursuit must be treated as a highly capitalized **deep-tech venture** requiring a multi-disciplinary team and a significant runway. Ignoring the risks detailed in the analysis will lead to certain failure.\\n\\n### 1. Execute the Phase 1 Scope Limitation (CHF Readmissions)\\n\\nThe most critical step is to simplify the initial technical and regulatory complexity.\\n\\n*   **Focus:** Target **reducing 30-day readmissions for post-discharge Congestive Heart Failure (CHF) patients.**\\n*   **Why CHF?** Medicare penalties are severe, the data inputs (weight, fluid status, BP, HRV) are relatively standardized, and the event (readmission) is clearly labeled and high-cost. This is the fastest route to demonstrating quantifiable ROI to a payer.\\n*   **Proof Point:** The initial success metric must be a peer-reviewed publication of a Randomized Controlled Trial (RCT) showing a statistically significant reduction in 30-day CHF readmission rates.\\n\\n### 2. Immediate Regulatory Strategy\\n\\nThe project cannot move forward without clarity on the regulatory path.\\n\\n*   **Priority:** Engage the FDA pre-submission process immediately. The \"Prescriptive Nudge System\" is highly likely to be deemed Software as a Medical Device (SaMD).\\n*   **Dual Track:** Structure the early product releases as a non-regulated **Clinical Decision Support (CDS)** tool while simultaneously running the necessary clinical trials for the SaMD designation. This allows for initial health system pilots (for data acquisition and training) while the rigorous validation proceeds in parallel.\\n\\n### 3. Team & Capital Requirements\\n\\nThis is not a lean startup endeavor.\\n\\n*   **Foundational Team:** Requires elite-level expertise in three non-negotiable areas:\\n    1.  **RL/Multimodal AI Modeling:** Deep scientific talent to fuse heterogeneous data.\\n    2.  **Clinical/Regulatory:** Individuals with experience achieving FDA clearance for high-risk devices.\\n    3.  **Enterprise Health IT/Data Engineering:** Specialists capable of integrating and securing data from dozens of disparate EHRs and consumer device APIs (the \"data plumbing\" risk).\\n*   **Capital:** The initial seed round and Series A must factor in the multi-year cost of integration, running an RCT, and achieving SaMD clearance, likely requiring 2-3x the typical runway for a standard B2B SaaS startup.\\n\\n## Conclusion\\n\\nKPH has the potential to be a defining company of the next decade in healthcare, possessing a value proposition that is unique and economically irresistible.\\n\\n**Decision: Pursue.** (But recognize that this venture carries the failure profile of biotech or aerospace, not typical software.)', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "# 3 corrected code\n",
    "# Missing system_message, Wrong response handling\n",
    "from autogen import ConversableAgent\n",
    "import os\n",
    "\n",
    "GEMINI_API_KEY=\"your key\"\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": \"models/gemini-flash-latest\",\n",
    "    \"api_key\": GEMINI_API_KEY,\n",
    "    \"api_type\": \"google\"\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 1️⃣ THINKER AGENT\n",
    "# =========================================================\n",
    "thinker = ConversableAgent(\n",
    "    name=\"Thinker\",\n",
    "    system_message=\"You generate innovative startup ideas in health tech.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 2️⃣ ANALYST AGENT\n",
    "# =========================================================\n",
    "analyst = ConversableAgent(\n",
    "    name=\"Analyst\",\n",
    "    system_message=\"You analyze the pros and cons of startup ideas.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3️⃣ DECISION MAKER AGENT\n",
    "# =========================================================\n",
    "decision_maker = ConversableAgent(\n",
    "    name=\"DecisionMaker\",\n",
    "    system_message=\"You decide whether the idea should be pursued.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 4️⃣ SEQUENTIAL AGENT FLOW\n",
    "# =========================================================\n",
    "idea = thinker.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Suggest an innovative startup idea in health tech\"}]\n",
    ")\n",
    "\n",
    "analysis = analyst.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"Analyze pros and cons:\\n{idea}\"}]\n",
    ")\n",
    "\n",
    "decision = decision_maker.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"Should we pursue this?\\n{analysis}\"}]\n",
    ")\n",
    "\n",
    "print(\"IDEA:\\n\", idea)\n",
    "print(\"\\nANALYSIS:\\n\", analysis)\n",
    "print(\"\\nDECISION:\\n\", decision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd76f697-ca9d-41a4-84e9-8de74955d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ REVIEW =================\n",
      "\n",
      "**Overall Assessment:**\n",
      "\n",
      "Your research makes a timely contribution to the field of natural language processing (NLP), particularly for underserved languages. The use of transformers has shown promising results in high-resource languages, and exploring its applicability to low-resource languages is a crucial step towards a more inclusive NLP ecosystem.\n",
      "\n",
      "However, there are areas that require revision and improvement. Here's my feedback based on your draft:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "1. **Relevance:** Your research is highly relevant to the current AI trends and has significant implications for NLP development in under-resourced languages.\n",
      "2. **Background knowledge:** You provide a good introduction to transformers, their applications, and limitations in high-resource languages, which helps readers understand the context of your study.\n",
      "\n",
      "**Weaknesses and Suggestions:**\n",
      "\n",
      "1. **Lack of clear objectives:** The abstract does not clearly state the research question or hypothesis being investigated. Could you please formulate specific questions or goals that this study aims to address?\n",
      "\n",
      "2. **Methodology clarity:** Some sections, such as experiment design and evaluation metrics, are vague or missing crucial details. I would appreciate it if you could expand on your methodology, especially for aspects where methods might be difficult to replicate.\n",
      "\n",
      "3. **Comparison with previous studies:** Are there any existing models or studies that have explored transformer adaptation in low-resource languages? If so, please discuss them briefly and highlight the uniqueness of your approach compared to prior works.\n",
      "\n",
      "4. **Dataset description:** While you mention selecting a particular dataset for evaluation, I couldn't find information on why this dataset was chosen over others or whether it underwent any preprocessing steps before model training. Including more context about your dataset selection process would be helpful for reproducibility.\n",
      "\n",
      "5. **Results presentation and discussion:** Although the introduction sets up an interesting premise, the results section seems meager in its contents. It might be useful to provide more numerical data to support the performance improvements observed with your transformer-adaptation approach.\n",
      "\n",
      "**Additional Comments:**\n",
      "\n",
      "1. A reference list or bibliography would improve readability by citing primary sources relevant to the use of transformers and low-resource languages.\n",
      "2. In some places, there is an obvious need for improved sentence-level clarity, which will facilitate better understanding by readers.\n",
      "\n",
      "================ EDITED VERSION =================\n",
      "\n",
      "Thank you for your detailed feedback! I'm glad to receive specific suggestions to enhance my research draft. Below are my revisions addressing each point:\n",
      "\n",
      "**Revised Abstract:**\n",
      "\n",
      "Our investigation aims to explore the adaptation of transformers to low-resource languages, building upon their successful applications in high-resource languages. We seek to answer two primary questions: (1) Can transformers achieve comparable or improved performance on low-resource languages compared to state-of-the-art models? (2) What challenges arise when adapting transformers to underserved languages, and how can they be mitigated?\n",
      "\n",
      "**Improved Introduction:**\n",
      "\n",
      "To provide context, we begin by reviewing the current literature on transformers and their widespread adoption in high-resource languages. However, the deployment of these models in low-resource contexts is limited due to issues with under-annotation, lack of parallel data, and hardware constraints. Recent studies have shown promise in adapting transformers for low-resource languages; our research expands upon this area by (1) investigating a novel architecture tailored specifically for low-resource settings and (2) evaluating the performance improvements using a carefully selected evaluation metric.\n",
      "\n",
      "**Enhanced Methodology Clarity:**\n",
      "\n",
      "We employ an experiment design that combines transfer learning, model customization, and fine-tuning. Specifically, we fine-tune our adapted transformer models on the selected dataset, followed by evaluation using a mix of common metrics (e.g., accuracy, BLEU score) and newly proposed measures tailored to low-resource languages.\n",
      "\n",
      "**Comparison with Previous Studies:**\n",
      "\n",
      "The recent studies exploring transformer adaptation in low-resource languages mainly focus on developing language-specific adapters or pre-training with limited parallel data. In contrast, our research leverages domain knowledge and linguistic features specific to the target languages. Furthermore, we extend earlier models by incorporating a combination of fine-tuning strategies tailored to underserved languages.\n",
      "\n",
      "**Dataset Description:**\n",
      "\n",
      "The selection of datasets was grounded in prior work on transformer applications for low-resource languages. Our dataset choice took into consideration both text characteristics (e.g., topic diversity) and availability. A key preprocessing step included data augmentation through synonymy expansion, which enhanced the model's capacity to generate diverse responses.\n",
      "\n",
      "**Results Presentation:**\n",
      "\n",
      "\n",
      "Our results reveal substantial performance gains when adapting transformers to underserved languages using our customized approach. We provide quantitative evidence on accuracy improvements over prior models (average absolute gains: 12%). Our analysis also highlights some critical points for future research in model personalization, such as identifying effective trade-offs between training data augmentation and fine-tuning steps.\n",
      "\n",
      "**Additional References:**\n",
      "\n",
      "To enhance readability, I will properly cite relevant sources throughout the paper. Additionally, for clarity's sake, I plan to provide a reference list at the end of the document.\n",
      "\n",
      "Thank you again for these constructive suggestions. Your feedback has greatly enhanced my research document, making it clear, concise, and ready for submission!\n",
      "\n",
      "================ SUMMARY =================\n",
      "\n",
      "It seems that you've made significant revisions to your draft based on my previous feedback. Here's a brief summary of your updates:\n",
      "\n",
      "* You've refined the abstract by clearly stating the questions your investigation aims to answer.\n",
      "* In the introduction, you've provided more context about the limitations of transformers in low-resource languages and emphasized your research's contributions.\n",
      "* Your enhanced methodology section now clarifies how you employed transfer learning, model customization, and fine-tuning to evaluate your adapters' performance.\n",
      "* You've distinguished your approach from previous studies by leveraging domain knowledge and linguistic features specific to target languages.\n",
      "* The revised dataset description highlights the text characteristics and preprocessing steps used to enhance model capacity.\n",
      "* Finally, you plan to cite sources and provide an reference list to maintain proper citation practices.\n",
      "\n",
      "Your revisions demonstrate a clear understanding of my feedback and a commitment to improving your research document. Your concise and concise writing should facilitate smooth submission proceedings.\n"
     ]
    }
   ],
   "source": [
    "# corrected Code\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 0️⃣ OLLAMA CONFIG (LOCAL, NO QUOTA)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"model\": \"llama3.1:8b\",\n",
    "    \"base_url\": \"http://localhost:11434/v1\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": \"ollama\",\n",
    "    \"price\": [0.0, 0.0],\n",
    "    \"timeout\": 60,        # ⏱ stop infinite wait\n",
    "    \"max_tokens\": 300     # ✂️ limit output length\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 1️⃣ HELPER FUNCTION (DICT-SAFE)\n",
    "# =========================================================\n",
    "def to_text(output):\n",
    "    if output is None:\n",
    "        return \"\"\n",
    "    if isinstance(output, dict):\n",
    "        return str(output)\n",
    "    if isinstance(output, list):\n",
    "        return \"\\n\".join(map(str, output))\n",
    "    return output\n",
    "\n",
    "# =========================================================\n",
    "# 2️⃣ REVIEWER AGENT\n",
    "# =========================================================\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"Reviewer\",\n",
    "    system_message=\"You are a research paper reviewer. Provide constructive feedback.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3️⃣ EDITOR AGENT\n",
    "# =========================================================\n",
    "editor = ConversableAgent(\n",
    "    name=\"Editor\",\n",
    "    system_message=\"You are an academic editor. Improve clarity and correctness.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 4️⃣ SUMMARIZER AGENT\n",
    "# =========================================================\n",
    "summarizer = ConversableAgent(\n",
    "    name=\"Summarizer\",\n",
    "    system_message=\"You summarize academic text concisely.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 5️⃣ SEQUENTIAL AGENT FLOW\n",
    "# =========================================================\n",
    "abstract = \"This research explores the use of transformers in low-resource languages.\"\n",
    "\n",
    "review = reviewer.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": abstract}]\n",
    ")\n",
    "\n",
    "edited = editor.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": to_text(review)}]\n",
    ")\n",
    "\n",
    "summary = summarizer.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": to_text(edited)}]\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 6️⃣ OUTPUT\n",
    "# =========================================================\n",
    "print(\"\\n================ REVIEW =================\\n\")\n",
    "print(to_text(review))\n",
    "\n",
    "print(\"\\n================ EDITED VERSION =================\\n\")\n",
    "print(to_text(edited))\n",
    "\n",
    "print(\"\\n================ SUMMARY =================\\n\")\n",
    "print(to_text(summary))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "594d77f9-5466-46ce-8ca5-05e30a01e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL SIMPLIFIED ANSWER:\n",
      "\n",
      "Here's a simple explanation:\n",
      "\n",
      "Quantum computing is a new way of processing information using special \"qubits\" that can do many things at the same time. This helps solve very hard problems that regular computers can't handle.\n",
      "\n",
      "Think of it like trying to find a specific book in a huge library. A regular computer would look through each shelf one by one, but a quantum computer could look at all shelves at the same time and find the right book instantly!\n"
     ]
    }
   ],
   "source": [
    "# corrected Code\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 0️⃣ FAST OLLAMA CONFIG\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"model\": \"llama3.1:8b\",\n",
    "    \"base_url\": \"http://localhost:11434/v1\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": \"ollama\",\n",
    "    \"price\": [0.0, 0.0],\n",
    "    \"timeout\": 45,\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 1️⃣ HELPER FUNCTION (DICT-SAFE)\n",
    "# =========================================================\n",
    "def to_text(output):\n",
    "    if output is None:\n",
    "        return \"\"\n",
    "    if isinstance(output, dict):\n",
    "        return str(output)\n",
    "    if isinstance(output, list):\n",
    "        return \"\\n\".join(map(str, output))\n",
    "    return output\n",
    "\n",
    "# =========================================================\n",
    "# 2️⃣ QUESTION AGENT\n",
    "# =========================================================\n",
    "question_agent = ConversableAgent(\n",
    "    name=\"QuestionAgent\",\n",
    "    system_message=\"Ask or restate the main question clearly in one sentence.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3️⃣ RESEARCH AGENT\n",
    "# =========================================================\n",
    "research_agent = ConversableAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    system_message=\"Provide a factual explanation in under 150 words.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 4️⃣ EXPLAINER AGENT\n",
    "# =========================================================\n",
    "explainer_agent = ConversableAgent(\n",
    "    name=\"ExplainerAgent\",\n",
    "    system_message=\"Explain the topic in very simple terms for a beginner, max 100 words.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 5️⃣ SEQUENTIAL AGENT FLOW\n",
    "# =========================================================\n",
    "q = question_agent.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is Quantum Computing?\"}]\n",
    ")\n",
    "\n",
    "r = research_agent.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": to_text(q)}]\n",
    ")\n",
    "\n",
    "e = explainer_agent.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": to_text(r)}]\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 6️⃣ OUTPUT\n",
    "# =========================================================\n",
    "print(\"\\nFINAL SIMPLIFIED ANSWER:\\n\")\n",
    "print(to_text(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b2d5d6-8b2a-4d9e-b8e1-b0c7787f615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " Global warming refers to the long-term increase in Earth's average surface temperature due to human activities, primarily the release of greenhouse gases like carbon dioxide and methane. This phenomenon leads to various environmental impacts, including more frequent and severe weather events, rising sea levels, and disruptions to ecosystems. Efforts to combat global warming include transitioning to renewable energy sources, improving energy efficiency, and implementing policies to reduce carbon emissions. Addressing global warming is crucial for the sustainability of the planet and future generations.\n",
      "\n",
      "Tamil Translation:\n",
      " உலகளாவிய வெப்பமயம்தல் என்பது மனித செயல்பாடுகள், குறிப்பாக கார்பன் டயொக்சைடு மற்றும் அதிகரிக்கப்பட்ட வாயுக்கள் போன்ற கசிபொருட்களின் வெளியீட்டினால் ஏற்படும் பூமியின் சராசரி மேல்மட்ட வெப்பநிலையிலான நீண்ட கால வளர்ச்சியைக் குறிக்கிறது. இந்த நிகழ்ச்சிப்பிரமாணத்திற்கு பல்வேறு சுற்றுச்கொண்டல் பாதிப்புகளை ஏற்படுத்துகிறது, அவற்றில் குறுகிய மற்றும் கடுமையான வானிலை நிகழ்வுகள், கடல்விளைவுகள், மற்றும் சுற்றுச்சூழல் மயங்கள் இடையாளிப்புகள் போன்றவை அடங்கும். உலகளாவிய வெப்பமயம்தலை எதிர்க்கும் முயற்சிகள் புதுப்பிக்கable வித்தியாச ஊட்டங்கள் நோக்கி மாறுதல், ஆற்றல் திறனை மேம்படுத்துதல், மற்றும் கார்பன் வெளியீடுகளை குறைக்க கொள்கைகளை செயல்படுத்துதல் ஆகியவற்றை உள்ளடக்கியவை. உலகளாவிய வெப்பமயம்தலை சரியான முறையில் கையாள்வது, பூமியின் நிலைத்தன்மைக்கு மற்றும் எதிர்கால தலைமுறைக்கு முக்கியமாக இருக்கிறது.\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1️⃣ LLM CONFIG (OLLAMA – OPENAI COMPATIBLE)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"api_key\": \"your key\"\n",
    "}\n",
    "# =========================================================\n",
    "# 2️⃣ AGENTS\n",
    "# =========================================================\n",
    "summarizer = ConversableAgent(\n",
    "    name=\"Summarizer\",\n",
    "    system_message=\"Summarize the given text clearly in 3–4 sentences.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "translator = ConversableAgent(\n",
    "    name=\"Translator\",\n",
    "    system_message=\"Translate the given text into Tamil.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3️⃣ SUMMARIZATION\n",
    "# =========================================================\n",
    "summary_text = summarizer.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Summarize the article about global warming.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Summary:\\n\", summary_text)\n",
    "\n",
    "# =========================================================\n",
    "# 4️⃣ TRANSLATION\n",
    "# =========================================================\n",
    "translation_text = translator.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": summary_text}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTamil Translation:\\n\", translation_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2ca57-d462-4739-b757-0161aadfae42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
