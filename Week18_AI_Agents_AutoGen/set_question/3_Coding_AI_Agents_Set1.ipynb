{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c07b33f-aa98-4cdb-a33d-b7f50dd9689f",
   "metadata": {},
   "source": [
    "# Coding AI Agents Set1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ed50d-f52f-4e0e-bcfa-fc09a483bd94",
   "metadata": {},
   "source": [
    "Question 1: Multi-Agent Role Interaction (Reviewer ‚ûù Editor ‚ûù Finalizer)\n",
    "Task: Implement a three-agent pipeline where each agent performs a unique role. Pass the message correctly to avoid format errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d85da91-e483-40bf-9222-809b9ca60d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORIGINAL TEXT:\n",
      " Global warming is a serious problem. It affects climate patterns, ecosystems, and human life.\n",
      "\n",
      "REVIEWER FEEDBACK:\n",
      " Here's some constructive feedback:\n",
      "\n",
      "The statement effectively conveys the importance of global warming as an issue. However, it could benefit from more specificity and depth to make its impact clearer.\n",
      "\n",
      "Some suggestions for improvement:\n",
      "\n",
      "* Consider adding specific examples or statistics to illustrate the effects of global warming on climate patterns, ecosystems, and human life. This would help readers understand the severity of the problem.\n",
      "* The language is quite general; using more precise terms or phrases could enhance the clarity and persuasiveness of the statement.\n",
      "* While the issue is framed as a \"serious problem,\" it might be helpful to provide some context or background information on why global warming is considered a pressing concern. This would give readers a better understanding of the urgency surrounding this topic.\n",
      "\n",
      "Overall, the statement provides a good starting point for discussing global warming, but could benefit from more detail and specificity to make its message more impactful.\n",
      "\n",
      "EDITED VERSION:\n",
      " Here's a revised version of the text incorporating the reviewer's feedback:\n",
      "\n",
      "Global warming is a pressing concern that poses significant threats to our planet. Rising temperatures are altering climate patterns, leading to extreme weather events such as intense hurricanes, droughts, and wildfires. For instance, 2020 saw record-breaking heatwaves in Europe, Australia, and North America, resulting in devastating losses of life and property.\n",
      "\n",
      "The impact on ecosystems is equally alarming. As global temperatures rise, many species are struggling to adapt, leading to a decline in biodiversity. According to the Intergovernmental Panel on Climate Change (IPCC), up to 1 million species face extinction due to human activities, with climate change being a primary driver. This not only has ecological consequences but also affects human well-being, as we rely on these ecosystems for food, water, and other essential resources.\n",
      "\n",
      "The effects of global warming on human life are far-reaching. Warmer temperatures increase the spread of diseases such as malaria and dengue fever\n",
      "\n",
      "FINAL OUTPUT:\n",
      " Here is a polished, publication-ready version of the text:\n",
      "\n",
      "**Global Warming: A Pressing Concern Threatening Our Planet**\n",
      "\n",
      "Rising global temperatures pose significant threats to our planet's ecosystems and human well-being. The consequences of climate change are far-reaching, with extreme weather events such as intense hurricanes, droughts, and wildfires becoming increasingly frequent.\n",
      "\n",
      "The past few years have seen devastating examples of the impact of global warming. In 2020, record-breaking heatwaves swept across Europe, Australia, and North America, resulting in significant loss of life and property. These events are not isolated incidents but rather symptoms of a larger problem.\n",
      "\n",
      "**Ecological Consequences**\n",
      "\n",
      "The effects of climate change on ecosystems are equally alarming. As temperatures rise, many species struggle to adapt, leading to a decline in biodiversity. According to the Intergovernmental Panel on Climate Change (IPCC), up to 1 million species face extinction due to human activities, with climate change being a primary driver. This not only\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Multi-Agent Role Interaction\n",
    "# Reviewer ‚ûù Editor ‚ûù Finalizer\n",
    "# Using AutoGen + Ollama (OpenAI-compatible)\n",
    "# =========================================================\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LLM CONFIG (OLLAMA)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3.1:8b\",\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_type\": \"openai\",\n",
    "            \"api_key\": \"ollama\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 200,\n",
    "            \"timeout\": 45,\n",
    "            \"price\": [0.0, 0.0]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ DEFINE AGENTS\n",
    "# =========================================================\n",
    "\n",
    "reviewer = ConversableAgent(\n",
    "    name=\"Reviewer\",\n",
    "    system_message=(\n",
    "        \"You are a reviewer. Analyze the text and provide constructive feedback. \"\n",
    "        \"Do not rewrite the content.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "editor = ConversableAgent(\n",
    "    name=\"Editor\",\n",
    "    system_message=(\n",
    "        \"You are an editor. Improve the text using the reviewer's feedback. \"\n",
    "        \"Focus on clarity, structure, and flow.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "finalizer = ConversableAgent(\n",
    "    name=\"Finalizer\",\n",
    "    system_message=(\n",
    "        \"You are a finalizer. Produce a polished, publication-ready version.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ INPUT TEXT\n",
    "# =========================================================\n",
    "original_text = (\n",
    "    \"Global warming is a serious problem. \"\n",
    "    \"It affects climate patterns, ecosystems, and human life.\"\n",
    ")\n",
    "\n",
    "print(\"\\nORIGINAL TEXT:\\n\", original_text)\n",
    "\n",
    "# =========================================================\n",
    "# 4Ô∏è‚É£ REVIEWER STEP\n",
    "# =========================================================\n",
    "review_feedback = reviewer.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": original_text}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nREVIEWER FEEDBACK:\\n\", review_feedback)\n",
    "\n",
    "# =========================================================\n",
    "# 5Ô∏è‚É£ EDITOR STEP\n",
    "# =========================================================\n",
    "editor_input = f\"\"\"\n",
    "Original Text:\n",
    "{original_text}\n",
    "\n",
    "Reviewer Feedback:\n",
    "{review_feedback}\n",
    "\"\"\"\n",
    "\n",
    "edited_text = editor.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": editor_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nEDITED VERSION:\\n\", edited_text)\n",
    "\n",
    "# =========================================================\n",
    "# 6Ô∏è‚É£ FINALIZER STEP\n",
    "# =========================================================\n",
    "final_text = finalizer.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": edited_text}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL OUTPUT:\\n\", final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17b6cd-6cf3-4e59-b420-8dd5306b02b3",
   "metadata": {},
   "source": [
    "Question 2: Language Translator ‚ûù Culture Rephraser\n",
    "Task: Use one agent to translate from English to French, then another to culturally rephrase the French text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306acca8-1d63-42ce-aeac-32760968e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üá¨üáß ENGLISH TEXT:\n",
      " Please let me know if you have any questions and feel free to reach out anytime.\n",
      "\n",
      "üá´üá∑ FRENCH TRANSLATION:\n",
      " Voici la traduction en fran√ßais :\n",
      "\n",
      "N'h√©sitez pas √† me poser des questions et n'ayez pas peur de me contacter √† tout moment.\n",
      "\n",
      "Translation notes:\n",
      "\n",
      "* \"Let me know\" is translated as \"n'h√©sitez pas √† me poser\", which is a more formal way of saying it.\n",
      "* \"Have any questions\" is translated as \"avoir des questions\", but in this context, \"n'avoir pas de questions\" (meaning \"don't have any questions\") would be more idiomatic.\n",
      "* \"Feel free to reach out\" is translated as \"n'ayez pas peur de me contacter\", which conveys the same idea of being approachable and available.\n",
      "\n",
      "üé≠ CULTURALLY REPHRASED FRENCH:\n",
      " Here's a rephrased version that sounds natural, polite, and culturally appropriate for a native French speaker:\n",
      "\n",
      "\"N'h√©sitez pas √† me poser des questions si vous en avez besoin. Vous pouvez me contacter √† tout moment sans crainte.\"\n",
      "\n",
      "I made some adjustments to the original translation to make it sound more idiomatic and natural in French:\n",
      "\n",
      "* Instead of \"n'avoir pas de questions\", I used \"si vous en avez besoin\" which is a more common way to express the idea that you're available to answer questions.\n",
      "* I changed \"n'ayez pas peur de me contacter\" to \"sans crainte\", which conveys the same idea of being approachable and available, but in a more concise and idiomatic way.\n",
      "\n",
      "This rephrased version should sound more natural and polite for a native French speaker.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Question 2: Language Translator ‚ûù Culture Rephraser\n",
    "# English ‚Üí French ‚Üí Cultural Rephrasing\n",
    "# Using AutoGen + OLLAMA (LOCAL, FREE)\n",
    "# =========================================================\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LLM CONFIG (OLLAMA ‚Äì OPENAI COMPATIBLE)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3.1:8b\",              # You may also use: mistral, qwen2.5\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_type\": \"openai\",\n",
    "            \"api_key\": \"ollama\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 200,\n",
    "            \"timeout\": 45,\n",
    "            \"price\": [0.0, 0.0]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ DEFINE AGENTS\n",
    "# =========================================================\n",
    "\n",
    "# Agent 1: TranslatorAgent\n",
    "translator_agent = ConversableAgent(\n",
    "    name=\"TranslatorAgent\",\n",
    "    system_message=(\n",
    "        \"You are a language translator. Translate the given English text \"\n",
    "        \"into clear, grammatically correct French.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent 2: CultureRephraserAgent\n",
    "culture_rephraser_agent = ConversableAgent(\n",
    "    name=\"CultureRephraserAgent\",\n",
    "    system_message=(\n",
    "        \"You are a cultural language expert. Rephrase the French text \"\n",
    "        \"to sound natural, polite, and culturally appropriate for a \"\n",
    "        \"native French speaker.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ SAMPLE INPUT TEXT (ENGLISH)\n",
    "# =========================================================\n",
    "english_text = (\n",
    "    \"Please let me know if you have any questions and feel free to reach out anytime.\"\n",
    ")\n",
    "\n",
    "print(\"\\nüá¨üáß ENGLISH TEXT:\\n\", english_text)\n",
    "\n",
    "# =========================================================\n",
    "# 4Ô∏è‚É£ TRANSLATION STEP (EN ‚Üí FR)\n",
    "# =========================================================\n",
    "french_translation = translator_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": english_text}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nüá´üá∑ FRENCH TRANSLATION:\\n\", french_translation)\n",
    "\n",
    "# =========================================================\n",
    "# 5Ô∏è‚É£ CULTURAL REPHRASING STEP\n",
    "# =========================================================\n",
    "culturally_rephrased_text = culture_rephraser_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": french_translation}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nüé≠ CULTURALLY REPHRASED FRENCH:\\n\", culturally_rephrased_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449d7f9-b61b-4da5-8f19-918aa4f676fc",
   "metadata": {},
   "source": [
    " Question 3: Code Generator ‚ûù Code Reviewer ‚ûù Bug  Fixer\n",
    "  Task: Have Agent A generate Python code, Agent B review it, and Agent C suggest bug fixes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0128b69-d089-40b2-872d-9c4ce9182eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TASK:\n",
      " Write a Python function to divide two numbers.\n",
      "\n",
      "GENERATED CODE:\n",
      " ```python\n",
      "def divide(a, b):\n",
      "    \"\"\"\n",
      "    Divide two numbers.\n",
      "\n",
      "    Args:\n",
      "        a (float): The dividend.\n",
      "        b (float): The divisor.\n",
      "\n",
      "    Returns:\n",
      "        float: The result of the division.\n",
      "\n",
      "    Raises:\n",
      "        ZeroDivisionError: If the divisor is zero.\n",
      "    \"\"\"\n",
      "    if b == 0:\n",
      "        raise ZeroDivisionError(\"Cannot divide by zero\")\n",
      "    return a / b\n",
      "```\n",
      "\n",
      "REVIEWER FEEDBACK:\n",
      " The code provided appears to be logically correct and follows good practices. However, here are some minor suggestions for improvement:\n",
      "\n",
      "1. **Docstring formatting**: The docstring is well-formatted, but it would be more consistent with Python's style guide (PEP 257) if the first line was a brief summary of the function's purpose.\n",
      "\n",
      "2. **Type hinting**: While the function parameters and return type are specified in the docstring, it's common to include these as type hints directly above the parameter list for clarity and consistency with other Python code.\n",
      "\n",
      "3. **Error message**: The error message raised when attempting to divide by zero is clear, but it might be more helpful to include a hint about what the user can do instead (e.g., \"Cannot divide by zero; please use a non-zero value for b\").\n",
      "\n",
      "Here's an example of how you could incorporate these suggestions:\n",
      "\n",
      "```python\n",
      "def divide(a: float, b: float) -> float:\n",
      "    \"\"\"\n",
      "    Divide two numbers.\n",
      "\n",
      "    Args:\n",
      "        a (float): The dividend.\n",
      "        b (float): The divisor.\n",
      "\n",
      "    Returns:\n",
      "        float: The result of the division.\n",
      "\n",
      "    Raises:\n",
      "        ZeroDivisionError: If the divisor is zero.\n",
      "    \"\"\"\n",
      "    if b == 0:\n",
      "        raise ZeroDivisionError(\"Cannot divide by zero; please use a non-zero value for b\")\n",
      "    return a / b\n",
      "```\n",
      "\n",
      "Overall, the code is well-written and follows good practices.\n",
      "\n",
      "FIXED CODE:\n",
      " ```python\n",
      "def divide(a: float, b: float) -> float:\n",
      "    \"\"\"\n",
      "    Divide two numbers.\n",
      "\n",
      "    Args:\n",
      "        a (float): The dividend.\n",
      "        b (float): The divisor.\n",
      "\n",
      "    Returns:\n",
      "        float: The result of the division.\n",
      "\n",
      "    Raises:\n",
      "        ZeroDivisionError: If the divisor is zero.\n",
      "    \"\"\"\n",
      "    if b == 0:\n",
      "        raise ZeroDivisionError(\"Cannot divide by zero; please use a non-zero value for b\")\n",
      "    return a / b\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Question 3: Code Generator ‚ûù Code Reviewer ‚ûù Bug Fixer\n",
    "# Using AutoGen + Ollama (OpenAI-compatible)\n",
    "# =========================================================\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LLM CONFIG (OLLAMA)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3.1:8b\",\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_type\": \"openai\",\n",
    "            \"api_key\": \"ollama\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 400,\n",
    "            \"timeout\": 45,\n",
    "            \"price\": [0.0, 0.0]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ DEFINE AGENTS\n",
    "# =========================================================\n",
    "\n",
    "# Agent A: Code Generator\n",
    "code_generator = ConversableAgent(\n",
    "    name=\"CodeGenerator\",\n",
    "    system_message=(\n",
    "        \"You are a Python developer. Generate clean Python code based on the user's request. \"\n",
    "        \"Do not explain the code.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent B: Code Reviewer\n",
    "code_reviewer = ConversableAgent(\n",
    "    name=\"CodeReviewer\",\n",
    "    system_message=(\n",
    "        \"You are a senior code reviewer. Review the given Python code and identify \"\n",
    "        \"logical errors, bugs, or bad practices. Do not fix the code.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent C: Bug Fixer\n",
    "bug_fixer = ConversableAgent(\n",
    "    name=\"BugFixer\",\n",
    "    system_message=(\n",
    "        \"You are a bug fixer. Fix the issues identified by the reviewer and return \"\n",
    "        \"the corrected Python code only.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ USER TASK\n",
    "# =========================================================\n",
    "task_prompt = \"Write a Python function to divide two numbers.\"\n",
    "\n",
    "print(\"\\nTASK:\\n\", task_prompt)\n",
    "\n",
    "# =========================================================\n",
    "# 4Ô∏è‚É£ CODE GENERATION STEP\n",
    "# =========================================================\n",
    "generated_code = code_generator.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": task_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nGENERATED CODE:\\n\", generated_code)\n",
    "\n",
    "# =========================================================\n",
    "# 5Ô∏è‚É£ CODE REVIEW STEP\n",
    "# =========================================================\n",
    "review_feedback = code_reviewer.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": generated_code}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nREVIEWER FEEDBACK:\\n\", review_feedback)\n",
    "\n",
    "# =========================================================\n",
    "# 6Ô∏è‚É£ BUG FIXING STEP\n",
    "# =========================================================\n",
    "bug_fixer_input = f\"\"\"\n",
    "Original Code:\n",
    "{generated_code}\n",
    "\n",
    "Reviewer Feedback:\n",
    "{review_feedback}\n",
    "\"\"\"\n",
    "\n",
    "fixed_code = bug_fixer.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": bug_fixer_input}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nFIXED CODE:\\n\", fixed_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ac081-26a4-477a-a140-eec250ec90dd",
   "metadata": {},
   "source": [
    "  Question 4: Email Response Automation using Multiple Agents\n",
    "   Task:\n",
    "    Create a 3-agent flow using ConversableAgent and Gemini:\n",
    "‚óè\tReaderAgent: Extracts main point from an email\n",
    "\n",
    "‚óè\tResponderAgent: Drafts a reply\n",
    "\n",
    "‚óè\tFormatterAgent: Formats it as a proper email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1d3b3c-4314-43f3-9805-97d6857c9efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì© INCOMING EMAIL:\n",
      " \n",
      "Subject: Meeting Reschedule Request\n",
      "\n",
      "Hi,\n",
      "\n",
      "Due to an unexpected conflict, I would like to reschedule tomorrow's meeting.\n",
      "Please let me know your availability for later this week.\n",
      "\n",
      "Thanks,\n",
      "Subramani\n",
      "\n",
      "\n",
      "üß† EXTRACTED MAIN POINT:\n",
      " The main intent of the email is to request a rescheduling of a meeting that was previously scheduled for tomorrow. The sender needs to find an alternative time slot later in the week.\n",
      "\n",
      "‚úçÔ∏è DRAFT REPLY:\n",
      " Here's a draft of a short and professional response:\n",
      "\n",
      "Subject: Re: Rescheduling Meeting for Tomorrow\n",
      "\n",
      "Dear [Recipient],\n",
      "\n",
      "Thank you for reaching out about the meeting scheduled for tomorrow. Unfortunately, I won't be able to make it at that time. Would it be possible to reschedule for later in the week? I am available [insert alternative days/times]. Please let me know if this works for you.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "\n",
      "‚úÖ FINAL FORMATTED EMAIL:\n",
      " Here is a properly formatted email:\n",
      "\n",
      "Subject: Re: Rescheduling Meeting for Tomorrow\n",
      "\n",
      "Dear John,\n",
      "\n",
      "Thank you for reaching out about the meeting scheduled for tomorrow. Unfortunately, I won't be able to make it at that time. Would it be possible to reschedule for later in the week? I am available on Wednesday or Thursday morning/afternoon. Please let me know if this works for you.\n",
      "\n",
      "Best regards,\n",
      "Emily Wilson\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Email Response Automation using Multiple Agents\n",
    "# ReaderAgent ‚ûù ResponderAgent ‚ûù FormatterAgent\n",
    "# Using AutoGen + OLLAMA (LOCAL, FREE)\n",
    "# =========================================================\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LLM CONFIG (OLLAMA ‚Äì OPENAI COMPATIBLE)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3.1:8b\",              # You can also use: mistral, qwen2.5\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_type\": \"openai\",\n",
    "            \"api_key\": \"ollama\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 150,\n",
    "            \"timeout\": 45,\n",
    "            \"price\": [0.0, 0.0]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ DEFINE AGENTS\n",
    "# =========================================================\n",
    "\n",
    "# Agent 1: ReaderAgent\n",
    "reader_agent = ConversableAgent(\n",
    "    name=\"ReaderAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email reader. Extract the main intent or key point \"\n",
    "        \"from the email in 1‚Äì2 short sentences.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent 2: ResponderAgent\n",
    "responder_agent = ConversableAgent(\n",
    "    name=\"ResponderAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email responder. Draft a short, professional reply \"\n",
    "        \"based on the extracted main point.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent 3: FormatterAgent\n",
    "formatter_agent = ConversableAgent(\n",
    "    name=\"FormatterAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email formatter. Format the response as a proper email \"\n",
    "        \"with Subject, Greeting, Body, and Signature.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ SAMPLE INPUT EMAIL\n",
    "# =========================================================\n",
    "incoming_email = \"\"\"\n",
    "Subject: Meeting Reschedule Request\n",
    "\n",
    "Hi,\n",
    "\n",
    "Due to an unexpected conflict, I would like to reschedule tomorrow's meeting.\n",
    "Please let me know your availability for later this week.\n",
    "\n",
    "Thanks,\n",
    "John\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüì© INCOMING EMAIL:\\n\", incoming_email)\n",
    "\n",
    "# =========================================================\n",
    "# 4Ô∏è‚É£ READER AGENT STEP\n",
    "# =========================================================\n",
    "main_point = reader_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": incoming_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nüß† EXTRACTED MAIN POINT:\\n\", main_point)\n",
    "\n",
    "# =========================================================\n",
    "# 5Ô∏è‚É£ RESPONDER AGENT STEP\n",
    "# =========================================================\n",
    "draft_reply = responder_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": main_point}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úçÔ∏è DRAFT REPLY:\\n\", draft_reply)\n",
    "\n",
    "# =========================================================\n",
    "# 6Ô∏è‚É£ FORMATTER AGENT STEP\n",
    "# =========================================================\n",
    "final_email = formatter_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": draft_reply}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ FINAL FORMATTED EMAIL:\\n\", final_email)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c31d5-f532-4a41-861e-8d7f669c90d1",
   "metadata": {},
   "source": [
    "Question 5: Meeting Transcript ‚Üí Action Points\n",
    "  Task:\n",
    "  Create a 3-agent pipeline to convert a meeting transcript into actionable tasks.\n",
    "‚óè\tListenerAgent: Extracts main discussion points\n",
    "\n",
    "‚óè\tActionAgent: Converts them into to-do tasks\n",
    "\n",
    "‚óè\tDeadlineAgent: Assigns timelines to each task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99487e19-b7e1-4aea-8cb3-34672306491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéôÔ∏è MEETING TRANSCRIPT:\n",
      " \n",
      "Project Meeting ‚Äì Monday\n",
      "\n",
      "We discussed the need to finalize the UI design by this week.\n",
      "The backend API integration is pending and should start soon.\n",
      "Testing needs to be planned after integration.\n",
      "The team also mentioned preparing documentation before release.\n",
      "\n",
      "\n",
      "üß† DISCUSSION POINTS:\n",
      " Here are the key discussion points from the meeting in clear bullet points:\n",
      "\n",
      "* Finalize UI design by this week\n",
      "* Start backend API integration as soon as possible\n",
      "* Plan testing schedule after API integration is complete\n",
      "* Prepare documentation for release before deployment\n",
      "\n",
      "‚úÖ ACTIONABLE TASKS:\n",
      " Based on the discussion points, I've created a list of clear, actionable to-do tasks:\n",
      "\n",
      "**Task List:**\n",
      "\n",
      "1. **UI Design Finalization**\n",
      "\t* Deadline: This week\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Review and finalize UI design with stakeholders and designers.\n",
      "2. **Backend API Integration**\n",
      "\t* Priority: High\n",
      "\t* Start Date: As soon as possible\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Begin integrating backend APIs with the frontend application.\n",
      "3. **Testing Schedule Planning**\n",
      "\t* Trigger: After API integration is complete\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Plan and schedule testing sessions to ensure thorough quality assurance.\n",
      "4. **Documentation Preparation**\n",
      "\t* Deadline: Before deployment\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Prepare comprehensive documentation for the release, including user guides, technical notes, and any other relevant information.\n",
      "\n",
      "**Additional Tasks**\n",
      "\n",
      "* Assign tasks to team members and track progress.\n",
      "\n",
      "\n",
      "üìÖ FINAL TASKS WITH DEADLINES:\n",
      " Here's an updated task list with realistic timelines and deadlines:\n",
      "\n",
      "**Task List:**\n",
      "\n",
      "1. **UI Design Finalization**\n",
      "\t* Deadline: This week (by Friday)\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Review and finalize UI design with stakeholders and designers.\n",
      "2. **Backend API Integration**\n",
      "\t* Priority: High\n",
      "\t* Start Date: Monday (next week)\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Begin integrating backend APIs with the frontend application. Estimated completion time: 3-4 days\n",
      "3. **Testing Schedule Planning**\n",
      "\t* Trigger: After API integration is complete (by Thursday next week)\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Plan and schedule testing sessions to ensure thorough quality assurance.\n",
      "\t* Deadline for planning: Next Friday\n",
      "4. **Documentation Preparation**\n",
      "\t* Deadline: 2 weeks before deployment (by next Wednesday)\n",
      "\t* Responsible: [Name]\n",
      "\t* Task: Prepare comprehensive documentation for the release,\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Question 5: Meeting Transcript ‚Üí Action Points\n",
    "# ListenerAgent ‚ûù ActionAgent ‚ûù DeadlineAgent\n",
    "# Using AutoGen + OLLAMA (LOCAL, FREE)\n",
    "# =========================================================\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# =========================================================\n",
    "# 1Ô∏è‚É£ LLM CONFIG (OLLAMA ‚Äì OPENAI COMPATIBLE)\n",
    "# =========================================================\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama3.1:8b\",              # You may also use: mistral, qwen2.5\n",
    "            \"base_url\": \"http://localhost:11434/v1\",\n",
    "            \"api_type\": \"openai\",\n",
    "            \"api_key\": \"ollama\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 200,\n",
    "            \"timeout\": 45,\n",
    "            \"price\": [0.0, 0.0]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 2Ô∏è‚É£ DEFINE AGENTS\n",
    "# =========================================================\n",
    "\n",
    "# Agent 1: ListenerAgent\n",
    "listener_agent = ConversableAgent(\n",
    "    name=\"ListenerAgent\",\n",
    "    system_message=(\n",
    "        \"You are a meeting listener. Extract the key discussion points \"\n",
    "        \"from the meeting transcript in clear bullet points.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent 2: ActionAgent\n",
    "action_agent = ConversableAgent(\n",
    "    name=\"ActionAgent\",\n",
    "    system_message=(\n",
    "        \"You are a project assistant. Convert the discussion points \"\n",
    "        \"into clear, actionable to-do tasks.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Agent 3: DeadlineAgent\n",
    "deadline_agent = ConversableAgent(\n",
    "    name=\"DeadlineAgent\",\n",
    "    system_message=(\n",
    "        \"You are a planner. Assign realistic timelines or deadlines \"\n",
    "        \"to each task.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3Ô∏è‚É£ SAMPLE MEETING TRANSCRIPT\n",
    "# =========================================================\n",
    "meeting_transcript = \"\"\"\n",
    "Project Meeting ‚Äì Monday\n",
    "\n",
    "We discussed the need to finalize the UI design by this week.\n",
    "The backend API integration is pending and should start soon.\n",
    "Testing needs to be planned after integration.\n",
    "The team also mentioned preparing documentation before release.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüéôÔ∏è MEETING TRANSCRIPT:\\n\", meeting_transcript)\n",
    "\n",
    "# =========================================================\n",
    "# 4Ô∏è‚É£ LISTENER AGENT STEP\n",
    "# =========================================================\n",
    "discussion_points = listener_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": meeting_transcript}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nüß† DISCUSSION POINTS:\\n\", discussion_points)\n",
    "\n",
    "# =========================================================\n",
    "# 5Ô∏è‚É£ ACTION AGENT STEP\n",
    "# =========================================================\n",
    "action_tasks = action_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": discussion_points}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ ACTIONABLE TASKS:\\n\", action_tasks)\n",
    "\n",
    "# =========================================================\n",
    "# 6Ô∏è‚É£ DEADLINE AGENT STEP\n",
    "# =========================================================\n",
    "final_tasks_with_deadlines = deadline_agent.generate_reply(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": action_tasks}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nüìÖ FINAL TASKS WITH DEADLINES:\\n\", final_tasks_with_deadlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b233ad-aa41-43a4-8590-58dddb9bd7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
